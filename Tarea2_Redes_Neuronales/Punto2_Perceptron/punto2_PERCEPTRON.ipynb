{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2. NN with Linear regression & perceptron, Problema 2\n",
    "\n",
    "## Fundamentos de inteligencia computacional\n",
    "## por: Juan Pablo Arango A. & Simón Zapata Caro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pydoc import help  # can type in the python console `help(name of function)` to get the documentation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from matplotlib.artist import setp\n",
    "import time\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1     = pd.io.excel.read_excel(\"DatosPunto2.xlsx\", sheetname=0)\n",
    "letters = df1.iloc[:,0].copy()\n",
    "df1 = df1.iloc[:,1:16].copy()\n",
    "#normalización min-max\n",
    "str_comp = 'ARNGOZPT'\n",
    "df1 = (df1-np.min(df1, axis = 0))/(np.max(df1, axis = 0)-np.min(df1, axis = 0))\n",
    "#df1 = (df1-np.mean(df1, axis = 0))/(np.std(df1, axis = 0))\n",
    "X = np.array(df1)\n",
    "\n",
    "y = -np.ones((X.shape[0],))\n",
    "i = 0\n",
    "for L in letters:\n",
    "    if str_comp.find(L) >= 0:\n",
    "        print('letra '+str(L)+' aparece en apellidos')\n",
    "        y[i] = 1\n",
    "    else:\n",
    "        print('letra '+str(L)+' no aparece en apellidos')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original = X\n",
    "\n",
    "Nsamples = X.shape[0]\n",
    "Ntrain   = int(0.7*Nsamples)\n",
    "Nval     = int(0.15*Nsamples)\n",
    "Ntest    = Nsamples-Ntrain-Nval\n",
    "\n",
    "X_test = X[(Nsamples-Ntest):Nsamples,:]\n",
    "y_test = y[(Nsamples-Ntest):Nsamples  ]\n",
    "\n",
    "Xv = X[0:(Nsamples-Ntest),:]\n",
    "yv = y[0:(Nsamples-Ntest)  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivating(fx):\n",
    "    difcoefs = [1,-1]\n",
    "    return np.convolve(fx,difcoefs,mode='same')\n",
    "\n",
    "def chunkIt(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out\n",
    "\n",
    "def clearList(L): #arroja una lista de L elementos vacios, no sabia de qué otra forma hacerla\n",
    "    listica = []\n",
    "    for i in range(0,L):\n",
    "        listica.append([]);\n",
    "    return listica\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def Perceptron_training(X,y,iteraciones=500,de_min=0.01):\n",
    "    w_array     = []\n",
    "    p_i         = []\n",
    "    \n",
    "    w_          = np.zeros(X.shape[1] + 1,)\n",
    "    n           = X.shape[0]\n",
    "    nf          = X.shape[1]\n",
    "    sw          = 0\n",
    "    j           = 0\n",
    "    index       = []\n",
    "    error_array = []\n",
    "    \n",
    "    while j < iteraciones and sw == 0:\n",
    "        print('iteración: '+str(j+1))\n",
    "        for i in range(0,n):\n",
    "            g1  = np.sum(w_*np.insert(X[i,:],0,1))\n",
    "            yp  = 2*sigmoid(g1)-1\n",
    "            if yp*y[i] <= 0:\n",
    "                w_ = w_ + np.insert(X[i,:],0,1)*y[i]\n",
    "        \n",
    "        w_array.append(w_)\n",
    "        predicted = []\n",
    "        for i in range(0,n):\n",
    "            predicted.append(Predict(X[i,:],w_))\n",
    "        p_i.append(predicted)\n",
    "        E = 0\n",
    "        for i in range(0,n):\n",
    "            if predicted[i]*y[i]<0:\n",
    "                E += -predicted[i]*y[i]\n",
    "        index.append(j)\n",
    "        error_array.append(E)\n",
    "        #print(d_error_array[j])\n",
    "        \n",
    "        #if np.abs(d_error_array[len(d_error_array)-1]) < de_min:\n",
    "        #   sw = 1\n",
    "        \n",
    "        j = j + 1\n",
    "    #print('Función de error: '+str(E[0])+' iterando ' +str(j)+' veces')\n",
    "    plt.plot(error_array,'b')\n",
    "    plt.title('función de error')\n",
    "    plt.xlabel('Iteraciones')\n",
    "    plt.show()\n",
    "    \n",
    "    iter_min = np.argmin(error_array)\n",
    "    print('iteracción óptima: '+str(iter_min)+ ', función de error: '+str(error_array[iter_min]))\n",
    "    return [w_array[iter_min],p_i[iter_min]]\n",
    "\n",
    "def Predict(X,w_):\n",
    "    g = np.dot(w_.T,np.insert(X,0,1))\n",
    "    return 2*sigmoid(g)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de la red neuronal usando validación bootstraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "X = Xv\n",
    "y = yv\n",
    "Nf = 10\n",
    "N  = X.shape[0]\n",
    "kf = KFold(n_splits=Nf)\n",
    "\n",
    "error_train = np.zeros((Nf,))\n",
    "error_val   = np.zeros((Nf,))\n",
    "k=0\n",
    "error_min = np.inf\n",
    "for train_index, test_index in kf.split(X):\n",
    "    wPerceptron = []\n",
    "    predicted1  = []\n",
    "    predicted2  = []\n",
    "    error1      = []\n",
    "    error2      = []\n",
    "    [wPerceptron,predicted1] = Perceptron_training(X[train_index],y[train_index],de_min=0.001)\n",
    "    ecm1[i] = np.sqrt(np.sum(((predicted1[i]-y[train_index])*(predicted1[i]-y[train_index])))/y[train_index].shape)[0]\n",
    "\n",
    "    p_i = []\n",
    "    for j in range(0,X[test_index].shape[0]):\n",
    "        p_i.append(Predict(X[test_index][j,:],wLMS[i]))\n",
    "    predicted2[i] = p_i\n",
    "    ecm2[i] = np.sqrt(np.sum(((predicted2[i]-y[test_index])*(predicted2[i]-y[test_index])))/y[test_index].shape)[0]\n",
    "\n",
    "    if(ecm2[i] < minE_val):\n",
    "        wLMS_optimo = wLMS[i]\n",
    "        minE_val = ecm2[i]\n",
    "        alphaOptimo = alpha[i]\n",
    "    print('validación ',(k+1),' Función de error: ',str(E),' iterando ',str(Ni),' veces, con alpha: ',str(alpha[i]))\n",
    "ecm_train[k,:] = ecm1\n",
    "ecm_val[k,:]   = ecm2\n",
    "k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[wPERC,predicted1] = Perceptron_training(X_train,y_train,iteraciones=50,de_min=0.001)\n",
    "Accuracy_train = np.sum(np.array(predicted1)*y_train > 0)/y_train.shape[0]\n",
    "predicted2 = []\n",
    "for j in range(0,X_val.shape[0]):\n",
    "    predicted2.append(Predict(X_val[j,:],wPERC))\n",
    "Accuracy_val = np.sum(np.array(predicted2)*y_val > 0)/y_val.shape[0]\n",
    "d = {'valores predichos': predicted2, 'etiquetas de validación' : y_val, 'multiplicación' : np.array(predicted2)*y_val}\n",
    "df = pd.DataFrame(data=d)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tasa de entrenamiento: '+ str(Accuracy_train)+', tasa de validación: '+str(Accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
